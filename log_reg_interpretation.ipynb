{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Refresher\n",
    "\n",
    "Based on [this resource](https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-how-do-i-interpret-odds-ratios-in-logistic-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def probability(logodds):\n",
    "    '''\n",
    "    This function takes log odds from linear regression \n",
    "    and translates to probability.\n",
    "    '''\n",
    "    return np.exp(logodds)/(1 + np.exp(logodds))\n",
    "\n",
    "def extract_odds_ratio(params):\n",
    "    print(round(np.exp(params), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>female</th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>hon</th>\n",
       "      <th>femalexmath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  female  read  write  math  hon  femalexmath\n",
       "0    1.0       0    57     52    41    0            0\n",
       "1    1.0       1    68     59    53    0           53\n",
       "2    1.0       0    44     33    54    0            0\n",
       "3    1.0       0    63     44    47    0            0\n",
       "4    1.0       0    47     52    57    0            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/sample.csv\")\n",
    "data = sm.add_constant(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with no predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s start with the simplest logistic regression, a model without any predictor variables.  In an equation, we are modeling $logit(p)=\\beta_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556775\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    hon   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      199\n",
      "Method:                           MLE   Df Model:                            0\n",
      "Date:                Fri, 03 Feb 2023   Pseudo R-squ.:               8.068e-11\n",
      "Time:                        17:52:55   Log-Likelihood:                -111.36\n",
      "converged:                       True   LL-Null:                       -111.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                       nan\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.1255      0.164     -6.845      0.000      -1.448      -0.803\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = sm.Logit(data['hon'], data['const']).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Formula notation, identical results\n",
    "# lr = smf.logit('hon ~ 1', data=data).fit()\n",
    "# lr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means $log(p/(1-p)) = -1.12546$.  What is $p$ here?  It turns out that $p$ is the overall probability of being in honors class (hon = 1).  Let’s take a look at the frequency table for hon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    151\n",
       "1     49\n",
       "Name: hon, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.hon.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So $p = 49 / (151 + 49) =  .245$. The odds are $.245/(1-.245) = .3245$ and the log of the odds (logit) is $log(.3245) = -1.12546$.  In other words, the intercept from the model with no predictor variables is the estimated log odds of being in honors class for the whole population of interest.  We can also transform the log of the odds back to a probability: $p = exp(-1.12546)/(1+exp(-1.12546)) = .245$, if we like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with a single dichotomous predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s go one step further by adding a binary predictor variable, female, to the model.  Writing it in an equation, the model describes the following linear relationship: $logit(p) = \\beta_0 + \\beta_1 * \\text{female}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.549016\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    hon   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      198\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Fri, 03 Feb 2023   Pseudo R-squ.:                 0.01394\n",
      "Time:                        17:52:55   Log-Likelihood:                -109.80\n",
      "converged:                       True   LL-Null:                       -111.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                   0.07811\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "female         0.5928      0.341      1.736      0.083      -0.076       1.262\n",
      "const         -1.4709      0.269     -5.469      0.000      -1.998      -0.944\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = sm.Logit(data['hon'], data[['female','const']]).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before trying to interpret the two parameters estimated above, let’s take a look at the crosstab of the variable hon with female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>female</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "female   0   1\n",
       "hon           \n",
       "0       74  77\n",
       "1       17  32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data.hon, data.female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our dataset, what are the odds of a male being in the honors class and what are the odds of a female being in the honors class?  We can manually calculate these odds from the table: for males, the odds of being in the honors class are $(17/91)/(74/91) = 17/74 = .23$; and for females, the odds of being in the honors class are $(32/109)/(77/109) = 32/77 = .42$.  The ratio of the odds for female to the odds for male is $(32/77)/(17/74) = (32*74)/(77*17) = 1.809$.  So the odds for males are 17 to 74, the odds for females are 32 to 77, and the odds for female are about 81% higher than the odds for males."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can relate the odds for males and females and the output from the logistic regression.  The intercept of -1.471 is the log odds for males since male is the reference group (`female = 0`).  Using the odds we calculated above for males, we can confirm this: $log(.23) = -1.47$.  The coefficient for female is the log of odds ratio between the female group and male group: $log(1.809) = .593$.  So we can get the odds ratio by exponentiating the coefficient for female. Most statistical packages display both the raw regression coefficients and the exponentiated coefficients for logistic regression models. It's a little bit manual in Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female    1.81\n",
      "const     0.23\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "extract_odds_ratio(lr.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with a single continuous predictor variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another simple example is a model with a single continuous predictor variable such as the model below.  It describes the relationship between students’ math scores and the log odds of being in an honors class, like this: $logit(p) = \\beta_0 + \\beta_1 * \\text{math}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.417683\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    hon   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      198\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Fri, 03 Feb 2023   Pseudo R-squ.:                  0.2498\n",
      "Time:                        17:52:55   Log-Likelihood:                -83.537\n",
      "converged:                       True   LL-Null:                       -111.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 8.718e-14\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "math           0.1563      0.026      6.105      0.000       0.106       0.207\n",
      "const         -9.7939      1.482     -6.610      0.000     -12.698      -6.890\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = sm.Logit(data['hon'], data[['math','const']]).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the estimated coefficient for the intercept is the log odds of a student with a math score of zero being in an honors class.  In other words, the odds of being in an honors class when the math score is zero is exp(-9.793942) = .00005579.  \n",
    "\n",
    "These odds are very low, but if we look at the distribution of the variable **math**, we will see that no one in the sample has math score lower than 30.  In fact, all the test scores in the data set were standardized around mean of 50 and standard deviation of 10.  So the intercept in this model corresponds to the log odds of being in an honors class when math is at the hypothetical value of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the coefficient for math?  The coefficient and intercept estimates give us the following equation:\n",
    "\n",
    "$log(p / (1 - p)) = logit(p) = -9.7939 + 0.1563 * \\text{math}$\n",
    "\n",
    "Let’s fix **math** at some value. We will use 54.  Then the conditional logit of being in an honors class when the **math** score is held at 54 is\n",
    "\n",
    "$log(p / (1 - p))(\\text{math} = 54) = -9.7939 + 0.1563 * 54$\n",
    "\n",
    "We can examine the effect of a one-unit increase in math score.  When the math score is held at 55, the conditional logit of being in an honors class is\n",
    "\n",
    "$log(p / (1 - p))(\\text{math} = 55) = -9.7939 + 0.1563 * 55$\n",
    "\n",
    "Taking the difference of the two equations, we have the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$log(p / (1 - p))(math=55) - log(p / (1 - p))(math = 54) = .1563$\n",
    "\n",
    "Or solved..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1563"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((-9.7939 + 0.1563 * 55) - (-9.7939 + 0.1563 * 54), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can say now that the coefficient for **math** is the difference in the log odds.  In other words, for a one-unit increase in the math score, the expected change in log odds is .1563404.\n",
    "\n",
    "Can we translate this change in log odds to the change in odds? Indeed, we can.  Recall that logarithm converts multiplication and division to addition and subtraction. Its inverse, the exponentiation converts addition and subtraction back to multiplication and division.  If we exponentiate both sides of our last equation, we have the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math     1.17\n",
      "const    0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "extract_odds_ratio(lr.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can say for a one-unit increase in math score, we expect to see about 17% increase in the odds of being in an honors class.  This 17% of increase does not depend on the value that math is held at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with multiple predictor variables and no interaction terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we can have multiple predictor variables in a logistic regression model: \n",
    "\n",
    "$logit(p) = \\beta_0 + \\beta_1 * x1 + ... + \\beta_k * xk$\n",
    "\n",
    "Applying such a model to our example dataset, each estimated coefficient is the expected change in the log odds of being in an honors class for a unit increase in the corresponding predictor variable holding the other predictor variables constant at certain value.  Each exponentiated coefficient is the ratio of two odds, or the change in odds in the multiplicative scale for a unit increase in the corresponding predictor variable holding other variables at certain value.  Here is an example:\n",
    "\n",
    "$logit(p) = \\beta_0 + \\beta_1 * \\text{math} + \\beta_2 * \\text{female} + \\beta_3 * \\text{read}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.390424\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    hon   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      196\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Fri, 03 Feb 2023   Pseudo R-squ.:                  0.2988\n",
      "Time:                        17:52:55   Log-Likelihood:                -78.085\n",
      "converged:                       True   LL-Null:                       -111.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 2.348e-14\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "math           0.1230      0.031      3.931      0.000       0.062       0.184\n",
      "female         0.9799      0.422      2.324      0.020       0.154       1.806\n",
      "read           0.0591      0.027      2.224      0.026       0.007       0.111\n",
      "const        -11.7702      1.711     -6.880      0.000     -15.123      -8.417\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "lr = sm.Logit(data['hon'], data[['math', 'female', 'read','const']]).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math      1.13\n",
      "female    2.66\n",
      "read      1.06\n",
      "const     0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "extract_odds_ratio(lr.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fitted model says that, holding **math** and **reading** at a fixed value, the odds of getting into an honors class for **females** (female = 1)over the odds of getting into an honors class for **males** (female = 0) is `exp(.9799) = 2.66`.  In terms of percent change, we can say that the odds for females are 166% higher than the odds for males.  The coefficient for math says that, holding female and reading at a fixed value, we will see 13% increase in the odds of getting into an honors class for a one-unit increase in math score since `exp(.1229589) = 1.13`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression with an interaction term of two predictor variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the previous examples, we have said that the regression coefficient of a variable corresponds to the change in log odds and its exponentiated form corresponds to the odds ratio.  This is only true when our model does not have any interaction terms.  When a model has interaction term(s) of two predictor variables, it attempts to describe how the effect of a predictor variable depends on the level/value of another predictor variable.  The interpretation of the regression coefficients become more involved.\n",
    "\n",
    "Let’s take a simple example.\n",
    "\n",
    "$$logit(p) = log(p/(1-p))= \\beta_0 + \\beta_1 * \\text{female} + \\beta_2 * \\text{math} + \\beta_3 * \\text{female} * \\text{math}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.399417\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                    hon   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      196\n",
      "Method:                           MLE   Df Model:                            3\n",
      "Date:                Fri, 03 Feb 2023   Pseudo R-squ.:                  0.2826\n",
      "Time:                        17:52:55   Log-Likelihood:                -79.883\n",
      "converged:                       True   LL-Null:                       -111.36\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.381e-13\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          -8.7458      2.129     -4.108      0.000     -12.919      -4.573\n",
      "female         -2.8999      3.094     -0.937      0.349      -8.964       3.165\n",
      "math            0.1294      0.036      3.605      0.000       0.059       0.200\n",
      "femalexmath     0.0670      0.053      1.253      0.210      -0.038       0.172\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create Interaction\n",
    "data['femalexmath'] = data['female'] * data['math']\n",
    "\n",
    "lr = sm.Logit(data['hon'], data[['const', 'female', 'math', 'femalexmath']]).fit()\n",
    "print(lr.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Formula notation, identical results. No need to create interaction var first\n",
    "# lr = smf.logit(formula='hon ~ female + math + female:math', data=data).fit()\n",
    "# lr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the presence of interaction term of female by math, we can no longer talk about the effect of `female`, holding all other variables at certain value, since it does not make sense to fix `math` and `female:math` at certain value and still allow `female` change from 0 to 1!\n",
    "\n",
    "In this simple example where we examine the interaction of a binary variable and a continuous variable, we can think that we actually have **two equations**: one for males and one for females.  For males `(female=0)`, the equation is simply\n",
    "\n",
    "$$logit(p) = log(p/(1-p))= \\beta_0 + \\beta_2 * \\text{math}$$\n",
    "\n",
    "For females, the equation is\n",
    "\n",
    "$$logit(p) = log(p/(1-p))= (\\beta_0 + \\beta_1) + (\\beta_2 + \\beta_3 ) * \\text{math}$$\n",
    "\n",
    "Now we can map the logistic regression output to these two equations. So we can say that the **coefficient for math is the effect of math when female = 0**.  More explicitly, we can say that for male students, a one-unit increase in math score yields a change in log odds of 0.13.  \n",
    "\n",
    "On the other hand, for the female students, a one-unit increase in math score yields a change in log odds of $(.13 + .067) = 0.197$.  In terms of odds ratios, we can say that for male students, the odds ratio is $exp(.13)  = 1.14$ for a one-unit increase in math score and the odds ratio for female students is $exp(.197) = 1.22$ for a one-unit increase in math score.  **The ratio of these two odds ratios (female over male) turns out to be the exponentiated coefficient for the interaction term of female by math: $1.22/1.14 = exp(.067) = 1.07$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const          0.00\n",
      "female         0.06\n",
      "math           1.14\n",
      "femalexmath    1.07\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "extract_odds_ratio(lr.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
