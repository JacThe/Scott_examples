{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso, Ridge, & Elastic Net Regression\n",
    "\n",
    "Based on this [YouTube Video](https://www.youtube.com/watch?v=ctmNq7FgbvI). Code is [HERE](https://github.com/StatQuest/ridge_lasso_elastic_net_demo/blob/master/ridge_lass_elastic_net_demo.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000 # 1000 samples\n",
    "p = 5000 # 5000 parameters to estimate\n",
    "real_p = 15 # 15 params will help predict the outcome, the others will just be random noise\n",
    "\n",
    "x = matrix(rnorm(n*p), nrow=n, ncol=p) # Randome matrix with n*p values, spread across n rows and p cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply will return a vector of 1,000 values that are the sums of the first 15 columns in x\n",
    "# This way only the first 15 params have anything to do with the outcome of interest\n",
    "y = apply(x[,1:real_p], 1, sum) + rnorm(n) # + rnorm(n) adds a little noise to the sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First param gives range to sample from (from 1 to n), second gives number of sample to draw (2/3 of n)\n",
    "train_rows = sample(1:n, .66*n)\n",
    "\n",
    "x.train = x[train_rows,] # Apply mask to x for test\n",
    "x.test = x[-train_rows,] # Apply opposite of mask to x for train\n",
    "\n",
    "# Repeat with y\n",
    "y.train = y[train_rows]\n",
    "y.test = y[-train_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit\n",
    "\n",
    "[Documentation](https://www.rdocumentation.org/packages/glmnet/versions/4.1-1/topics/cv.glmnet) for `cv.glmnet()` and [documentation](https://www.rdocumentation.org/packages/glmnet/versions/4.1-1/topics/glmnet) for `glmnet()` for which `cv.glmnet()` wraps a cv function around in order to get the best Lambda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When alpha is set to 0, cv.glmnet() does a Ridge regression\n",
    "\n",
    "alpha0.fit = cv.glmnet(\n",
    "    x=x.train,\n",
    "    y=y.train,\n",
    "    type.measure='mse',\n",
    "    nfolds=10,\n",
    "    alpha=0.1,\n",
    "    family='gaussian' # This arg is passed through to glmnet()\n",
    ")\n",
    "\n",
    "alpha0.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the coefficients drop off in value at V16 and beyond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(alpha0.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict\n",
    "[Documentation](https://www.rdocumentation.org/packages/glmnet/versions/1.1-1/topics/predict.glmnet) for `predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0.predicted = predict(\n",
    "    object=alpha0.fit,\n",
    "    newx=x.test,\n",
    "    s=alpha0.fit$lambda.1se\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((y.test - alpha0.predicted)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When alpha is set to 1, glmnet() does a Lasso regression\n",
    "\n",
    "alpha1.fit = cv.glmnet(\n",
    "    x=x.train,\n",
    "    y=y.train,\n",
    "    type.measure='mse',\n",
    "    nfolds=10,\n",
    "    alpha=1,\n",
    "    family='gaussian' # This arg is passed through to glmnet()\n",
    ")\n",
    "\n",
    "alpha1.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the coefficients are mostly zero from V16 onward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef(alpha1.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha1.predicted = predict(\n",
    "    object=alpha1.fit,\n",
    "    newx=x.test,\n",
    "    s=alpha1.fit$lambda.1se\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((y.test - alpha1.predicted)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When alpha is set to 1, glmnet() does a Lasso regression\n",
    "\n",
    "alpha0.5.fit = cv.glmnet(\n",
    "    x=x.train,\n",
    "    y=y.train,\n",
    "    type.measure='mse',\n",
    "    nfolds=10,\n",
    "    alpha=0.5,\n",
    "    family='gaussian' # This arg is passed through to glmnet()\n",
    ")\n",
    "\n",
    "alpha0.5.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha0.5.predicted = predict(\n",
    "    object=alpha0.5.fit,\n",
    "    newx=x.test,\n",
    "    s=alpha0.5.fit$lambda.1se\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean((y.test - alpha0.5.predicted)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter Tuning for `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store information\n",
    "list.of.fits = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through 11 values\n",
    "\n",
    "for (i in 0:10) {\n",
    "    print(paste0(\"Fitting at alpha = \", i/10))\n",
    "    \n",
    "    # Name the element\n",
    "    fit.name = paste0(\"alpha\", i/10)\n",
    "    \n",
    "    # Train the model\n",
    "    list.of.fits[[fit.name]] = cv.glmnet(\n",
    "        x=x.train,\n",
    "        y=y.train,\n",
    "        type.measure='mse',\n",
    "        nfolds=10,\n",
    "        alpha=i/10,\n",
    "        family='gaussian' # This arg is passed through to glmnet()\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through 11 values\n",
    "\n",
    "results = data.frame() # Initialize empty df\n",
    "\n",
    "for (i in 0:10) {\n",
    "    print(paste0(\"Predicting at alpha = \", i/10))\n",
    "    \n",
    "    # Name the element\n",
    "    fit.name = paste0(\"alpha\", i/10)\n",
    "    \n",
    "    # Predict\n",
    "    predicted = predict(\n",
    "        object=list.of.fits[[fit.name]],\n",
    "        newx=x.test,\n",
    "        s=list.of.fits[[fit.name]]$lambda.1se\n",
    "    )\n",
    "        \n",
    "    mse = mean((y.test - predicted)^2)\n",
    "        \n",
    "    temp = data.frame(alpha=i/10, mse=mse, fit.name=fit.name)\n",
    "    print(temp)\n",
    "    \n",
    "    results = rbind(results, temp)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Since `mse` is lowest at `alpha=1`, **lasso** is still our best model! Might vary from time to time due to randomness, but `alpha=1` should be lowest or within just a few fractions of a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:linear_models]",
   "language": "R",
   "name": "conda-env-linear_models-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
